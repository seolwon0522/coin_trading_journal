"""
1ë…„ì¹˜ ë°±í…ŒìŠ¤íŠ¸ ë° ML ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ ë„êµ¬
- ê±°ë˜ ì„±ê³¼ ë¶„ì„
- ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
- ì‹œê°í™” ë° ë¦¬í¬íŠ¸ ìƒì„±
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
from datetime import datetime, timedelta
import logging
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

logger = logging.getLogger(__name__)

class BacktestAnalyzer:
    """ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„ê¸°"""
    
    def __init__(self):
        """ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        self.backtest_data = None
        self.model_metrics = {}
        
    def load_backtest_results(self, results_dir: str = "data/backtest_results") -> pd.DataFrame:
        """
        ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¡œë“œ
        
        Args:
            results_dir: ê²°ê³¼ ë””ë ‰í† ë¦¬
            
        Returns:
            í†µí•©ëœ ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„°
        """
        logger.info(f"ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¡œë“œ ì¤‘: {results_dir}")
        
        backtest_files = list(Path(results_dir).glob("*.csv"))
        
        if not backtest_files:
            logger.warning("ë°±í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
        
        # í•œê¸€ ì£¼ì„: ëª¨ë“  ë°±í…ŒìŠ¤íŠ¸ íŒŒì¼ í†µí•©
        all_data = []
        for file_path in backtest_files:
            try:
                df = pd.read_csv(file_path)
                df['source_file'] = file_path.name
                all_data.append(df)
                logger.info(f"ë¡œë“œ ì™„ë£Œ: {file_path.name} ({len(df)}ê±´)")
            except Exception as e:
                logger.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {file_path}: {e}")
        
        if all_data:
            self.backtest_data = pd.concat(all_data, ignore_index=True)
            logger.info(f"ì´ {len(self.backtest_data)}ê±´ì˜ ê±°ë˜ ë¡œë“œ")
        else:
            self.backtest_data = pd.DataFrame()
        
        return self.backtest_data
    
    def analyze_trading_performance(self) -> Dict:
        """
        ê±°ë˜ ì„±ê³¼ ë¶„ì„
        
        Returns:
            ì„±ê³¼ ë¶„ì„ ê²°ê³¼
        """
        if self.backtest_data is None or len(self.backtest_data) == 0:
            logger.warning("ë¶„ì„í•  ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return {}
        
        df = self.backtest_data.copy()
        
        # í•œê¸€ ì£¼ì„: ê¸°ë³¸ í†µê³„
        total_trades = len(df)
        winning_trades = len(df[df['return_pct'] > 0])
        losing_trades = len(df[df['return_pct'] < 0])
        
        win_rate = winning_trades / total_trades * 100 if total_trades > 0 else 0
        
        # í•œê¸€ ì£¼ì„: ìˆ˜ìµë¥  í†µê³„
        total_return = df['return_pct'].sum()
        avg_return = df['return_pct'].mean()
        avg_winning_return = df[df['return_pct'] > 0]['return_pct'].mean() if winning_trades > 0 else 0
        avg_losing_return = df[df['return_pct'] < 0]['return_pct'].mean() if losing_trades > 0 else 0
        
        # í•œê¸€ ì£¼ì„: ë¦¬ìŠ¤í¬ ë©”íŠ¸ë¦­
        volatility = df['return_pct'].std()
        sharpe_ratio = avg_return / volatility if volatility > 0 else 0
        
        # í•œê¸€ ì£¼ì„: ìµœëŒ€ ë‚™í­
        cumulative_returns = (1 + df['return_pct'] / 100).cumprod()
        running_max = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - running_max) / running_max * 100
        max_drawdown = drawdown.min()
        
        # í•œê¸€ ì£¼ì„: ê±°ë˜ ì§€ì†ì‹œê°„
        if 'duration_minutes' in df.columns:
            avg_trade_duration = df['duration_minutes'].mean()
            max_trade_duration = df['duration_minutes'].max()
        else:
            avg_trade_duration = None
            max_trade_duration = None
        
        performance_metrics = {
            'basic_stats': {
                'total_trades': total_trades,
                'winning_trades': winning_trades,
                'losing_trades': losing_trades,
                'win_rate_pct': round(win_rate, 2)
            },
            'returns': {
                'total_return_pct': round(total_return, 2),
                'avg_return_pct': round(avg_return, 4),
                'avg_winning_return_pct': round(avg_winning_return, 4),
                'avg_losing_return_pct': round(avg_losing_return, 4)
            },
            'risk_metrics': {
                'volatility_pct': round(volatility, 4),
                'sharpe_ratio': round(sharpe_ratio, 4),
                'max_drawdown_pct': round(max_drawdown, 2)
            },
            'trade_duration': {
                'avg_duration_minutes': round(avg_trade_duration, 1) if avg_trade_duration else None,
                'max_duration_minutes': max_trade_duration
            }
        }
        
        logger.info(f"ê±°ë˜ ì„±ê³¼ ë¶„ì„ ì™„ë£Œ: ìŠ¹ë¥  {win_rate:.1f}%, ìƒ¤í”„ë¹„ìœ¨ {sharpe_ratio:.3f}")
        return performance_metrics
    
    def load_model_metrics(self, models_dir: str = "data/models") -> Dict:
        """
        ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œë“œ
        
        Args:
            models_dir: ëª¨ë¸ ë””ë ‰í† ë¦¬
            
        Returns:
            ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­
        """
        logger.info(f"ëª¨ë¸ ë©”íŠ¸ë¦­ ë¡œë“œ ì¤‘: {models_dir}")
        
        metadata_files = list(Path(models_dir).glob("*metadata*.json"))
        
        if not metadata_files:
            logger.warning("ëª¨ë¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return {}
        
        # í•œê¸€ ì£¼ì„: ìµœì‹  ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        latest_metadata = max(metadata_files, key=lambda f: f.stat().st_mtime)
        
        try:
            with open(latest_metadata, 'r') as f:
                self.model_metrics = json.load(f)
            
            logger.info(f"ëª¨ë¸ ë©”íŠ¸ë¦­ ë¡œë“œ ì™„ë£Œ: {latest_metadata.name}")
            return self.model_metrics
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë©”íŠ¸ë¦­ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def create_performance_visualizations(self, save_dir: str = "data/reports/charts"):
        """
        ì„±ê³¼ ì‹œê°í™” ìƒì„±
        
        Args:
            save_dir: ì°¨íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        if self.backtest_data is None or len(self.backtest_data) == 0:
            logger.warning("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        Path(save_dir).mkdir(parents=True, exist_ok=True)
        
        df = self.backtest_data.copy()
        
        # í•œê¸€ ì£¼ì„: 1. ìˆ˜ìµë¥  ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
        plt.figure(figsize=(12, 8))
        
        plt.subplot(2, 2, 1)
        plt.hist(df['return_pct'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        plt.axvline(df['return_pct'].mean(), color='red', linestyle='--', label=f'í‰ê· : {df["return_pct"].mean():.3f}%')
        plt.title('ê±°ë˜ ìˆ˜ìµë¥  ë¶„í¬')
        plt.xlabel('ìˆ˜ìµë¥  (%)')
        plt.ylabel('ë¹ˆë„')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # í•œê¸€ ì£¼ì„: 2. ëˆ„ì  ìˆ˜ìµë¥  ê³¡ì„ 
        plt.subplot(2, 2, 2)
        cumulative_returns = (1 + df['return_pct'] / 100).cumprod()
        plt.plot(cumulative_returns.index, cumulative_returns.values, linewidth=2, color='green')
        plt.title('ëˆ„ì  ìˆ˜ìµë¥  ê³¡ì„ ')
        plt.xlabel('ê±°ë˜ ë²ˆí˜¸')
        plt.ylabel('ëˆ„ì  ìˆ˜ìµë¥ ')
        plt.grid(True, alpha=0.3)
        
        # í•œê¸€ ì£¼ì„: 3. ìˆ˜ìµ/ì†ì‹¤ ê±°ë˜ ë¹„êµ
        plt.subplot(2, 2, 3)
        winning_trades = df[df['return_pct'] > 0]['return_pct']
        losing_trades = df[df['return_pct'] < 0]['return_pct']
        
        labels = ['ìˆ˜ìµ ê±°ë˜', 'ì†ì‹¤ ê±°ë˜']
        counts = [len(winning_trades), len(losing_trades)]
        colors = ['green', 'red']
        
        plt.pie(counts, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
        plt.title('ìˆ˜ìµ/ì†ì‹¤ ê±°ë˜ ë¹„ìœ¨')
        
        # í•œê¸€ ì£¼ì„: 4. ì›”ë³„ ì„±ê³¼ (timestampê°€ ìˆëŠ” ê²½ìš°)
        plt.subplot(2, 2, 4)
        if 'timestamp' in df.columns:
            try:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                df['month'] = df['timestamp'].dt.to_period('M')
                monthly_returns = df.groupby('month')['return_pct'].sum()
                
                monthly_returns.plot(kind='bar', color='purple', alpha=0.7)
                plt.title('ì›”ë³„ ì´ ìˆ˜ìµë¥ ')
                plt.xlabel('ì›”')
                plt.ylabel('ìˆ˜ìµë¥  (%)')
                plt.xticks(rotation=45)
                plt.grid(True, alpha=0.3)
            except:
                plt.text(0.5, 0.5, 'ì›”ë³„ ë°ì´í„°\në¶„ì„ ë¶ˆê°€', ha='center', va='center', transform=plt.gca().transAxes)
                plt.title('ì›”ë³„ ì„±ê³¼')
        else:
            plt.text(0.5, 0.5, 'íƒ€ì„ìŠ¤íƒ¬í”„\në°ì´í„° ì—†ìŒ', ha='center', va='center', transform=plt.gca().transAxes)
            plt.title('ì›”ë³„ ì„±ê³¼')
        
        plt.tight_layout()
        
        # í•œê¸€ ì£¼ì„: ì°¨íŠ¸ ì €ì¥
        chart_path = Path(save_dir) / f"performance_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ì„±ê³¼ ì‹œê°í™” ì €ì¥: {chart_path}")
        
        # í•œê¸€ ì£¼ì„: ë“œë¡œìš°ë‹¤ìš´ ì°¨íŠ¸ ë³„ë„ ìƒì„±
        self._create_drawdown_chart(df, save_dir)
    
    def _create_drawdown_chart(self, df: pd.DataFrame, save_dir: str):
        """ë“œë¡œìš°ë‹¤ìš´ ì°¨íŠ¸ ìƒì„±"""
        
        cumulative_returns = (1 + df['return_pct'] / 100).cumprod()
        running_max = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - running_max) / running_max * 100
        
        plt.figure(figsize=(12, 6))
        
        plt.subplot(2, 1, 1)
        plt.plot(cumulative_returns.index, cumulative_returns.values, linewidth=2, color='blue', label='ëˆ„ì  ìˆ˜ìµë¥ ')
        plt.plot(running_max.index, running_max.values, linewidth=1, color='red', linestyle='--', label='ìµœê³ ì ')
        plt.title('ëˆ„ì  ìˆ˜ìµë¥ ê³¼ ìµœê³ ì ')
        plt.ylabel('ëˆ„ì  ìˆ˜ìµë¥ ')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.subplot(2, 1, 2)
        plt.fill_between(drawdown.index, drawdown.values, 0, color='red', alpha=0.3)
        plt.plot(drawdown.index, drawdown.values, linewidth=2, color='red')
        plt.title(f'ë“œë¡œìš°ë‹¤ìš´ (ìµœëŒ€: {drawdown.min():.2f}%)')
        plt.xlabel('ê±°ë˜ ë²ˆí˜¸')
        plt.ylabel('ë“œë¡œìš°ë‹¤ìš´ (%)')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        drawdown_path = Path(save_dir) / f"drawdown_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(drawdown_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ë“œë¡œìš°ë‹¤ìš´ ì°¨íŠ¸ ì €ì¥: {drawdown_path}")
    
    def generate_comprehensive_report(self, save_path: str = None) -> Dict:
        """
        ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            save_path: ë¦¬í¬íŠ¸ ì €ì¥ ê²½ë¡œ
            
        Returns:
            ì¢…í•© ë¦¬í¬íŠ¸
        """
        logger.info("ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        # í•œê¸€ ì£¼ì„: ê±°ë˜ ì„±ê³¼ ë¶„ì„
        trading_performance = self.analyze_trading_performance()
        
        # í•œê¸€ ì£¼ì„: ëª¨ë¸ ì„±ëŠ¥ ë¡œë“œ
        model_performance = self.load_model_metrics()
        
        # í•œê¸€ ì£¼ì„: ì‹œê°í™” ìƒì„±
        self.create_performance_visualizations()
        
        # í•œê¸€ ì£¼ì„: ì¢…í•© ë¦¬í¬íŠ¸ êµ¬ì„±
        comprehensive_report = {
            'report_metadata': {
                'generated_at': datetime.now().isoformat(),
                'analysis_period': '1_year_backtest',
                'total_data_points': len(self.backtest_data) if self.backtest_data is not None else 0
            },
            'trading_performance': trading_performance,
            'model_performance': model_performance.get('metrics', {}),
            'key_insights': self._generate_key_insights(trading_performance, model_performance),
            'recommendations': self._generate_recommendations(trading_performance, model_performance)
        }
        
        # í•œê¸€ ì£¼ì„: ë¦¬í¬íŠ¸ ì €ì¥
        if save_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = f"data/reports/comprehensive_report_{timestamp}.json"
        
        Path(save_path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ì¢…í•© ë¦¬í¬íŠ¸ ì €ì¥: {save_path}")
        return comprehensive_report
    
    def _generate_key_insights(self, trading_perf: Dict, model_perf: Dict) -> List[str]:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        
        if trading_perf.get('basic_stats'):
            win_rate = trading_perf['basic_stats']['win_rate_pct']
            total_trades = trading_perf['basic_stats']['total_trades']
            
            if win_rate > 60:
                insights.append(f"ë†’ì€ ìŠ¹ë¥  ë‹¬ì„±: {win_rate:.1f}% (ì´ {total_trades:,}ê±´ ê±°ë˜)")
            elif win_rate > 45:
                insights.append(f"ì ì • ìŠ¹ë¥  ìœ ì§€: {win_rate:.1f}% (ì´ {total_trades:,}ê±´ ê±°ë˜)")
            else:
                insights.append(f"ìŠ¹ë¥  ê°œì„  í•„ìš”: {win_rate:.1f}% (ì´ {total_trades:,}ê±´ ê±°ë˜)")
        
        if trading_perf.get('risk_metrics'):
            sharpe = trading_perf['risk_metrics']['sharpe_ratio']
            mdd = trading_perf['risk_metrics']['max_drawdown_pct']
            
            if sharpe > 1.0:
                insights.append(f"ìš°ìˆ˜í•œ ìœ„í—˜ì¡°ì •ìˆ˜ìµë¥ : ìƒ¤í”„ë¹„ìœ¨ {sharpe:.3f}")
            elif sharpe > 0.5:
                insights.append(f"ì–‘í˜¸í•œ ìœ„í—˜ì¡°ì •ìˆ˜ìµë¥ : ìƒ¤í”„ë¹„ìœ¨ {sharpe:.3f}")
            else:
                insights.append(f"ìœ„í—˜ì¡°ì •ìˆ˜ìµë¥  ê°œì„  í•„ìš”: ìƒ¤í”„ë¹„ìœ¨ {sharpe:.3f}")
                
            if abs(mdd) < 10:
                insights.append(f"ì•ˆì •ì ì¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬: ìµœëŒ€ë‚™í­ {mdd:.1f}%")
            else:
                insights.append(f"ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì£¼ì˜ í•„ìš”: ìµœëŒ€ë‚™í­ {mdd:.1f}%")
        
        if model_perf.get('test_r2'):
            r2 = model_perf['test_r2']
            if r2 > 0.3:
                insights.append(f"ë†’ì€ ì˜ˆì¸¡ ì„±ëŠ¥: RÂ² {r2:.3f}")
            elif r2 > 0.1:
                insights.append(f"ì ì • ì˜ˆì¸¡ ì„±ëŠ¥: RÂ² {r2:.3f}")
            else:
                insights.append(f"ì˜ˆì¸¡ ì„±ëŠ¥ ê°œì„  í•„ìš”: RÂ² {r2:.3f}")
        
        return insights
    
    def _generate_recommendations(self, trading_perf: Dict, model_perf: Dict) -> List[str]:
        """ê°œì„  ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # í•œê¸€ ì£¼ì„: ê±°ë˜ ì„±ê³¼ ê¸°ë°˜ ì¶”ì²œ
        if trading_perf.get('basic_stats', {}).get('win_rate_pct', 0) < 45:
            recommendations.append("ì „ëµ ì„ê³„ê°’ì„ ì¡°ì •í•˜ì—¬ ê±°ë˜ í’ˆì§ˆì„ ê°œì„ í•˜ì„¸ìš”")
        
        if trading_perf.get('risk_metrics', {}).get('sharpe_ratio', 0) < 0.5:
            recommendations.append("í¬ì§€ì…˜ ì‚¬ì´ì§•ê³¼ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë¡œì§ì„ ê°•í™”í•˜ì„¸ìš”")
        
        if abs(trading_perf.get('risk_metrics', {}).get('max_drawdown_pct', 0)) > 15:
            recommendations.append("ìµœëŒ€ë‚™í­ ê´€ë¦¬ë¥¼ ìœ„í•œ ì†ì ˆë§¤ ë¡œì§ì„ ê°œì„ í•˜ì„¸ìš”")
        
        # í•œê¸€ ì£¼ì„: ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ
        if model_perf.get('test_r2', 0) < 0.1:
            recommendations.append("í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì„ ê°œì„ í•˜ì—¬ ëª¨ë¸ ì˜ˆì¸¡ë ¥ì„ ë†’ì´ì„¸ìš”")
        
        if model_perf.get('overfit_ratio', 0) > 0.1:
            recommendations.append("ì •ê·œí™” íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ì„¸ìš”")
        
        # í•œê¸€ ì£¼ì„: ì¼ë°˜ì ì¸ ì¶”ì²œ
        total_trades = trading_perf.get('basic_stats', {}).get('total_trades', 0)
        if total_trades < 1000:
            recommendations.append("ë” ë§ì€ ê±°ë˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í†µê³„ì  ì‹ ë¢°ì„±ì„ ë†’ì´ì„¸ìš”")
        
        if not recommendations:
            recommendations.append("í˜„ì¬ ì„±ëŠ¥ì´ ì–‘í˜¸í•©ë‹ˆë‹¤. ë¼ì´ë¸Œ íŠ¸ë ˆì´ë”©ì„ ê³ ë ¤í•´ë³´ì„¸ìš”")
        
        return recommendations

def quick_analysis(
    backtest_dir: str = "data/backtest_results",
    models_dir: str = "data/models"
) -> Dict:
    """
    ë¹ ë¥¸ ë¶„ì„ ì‹¤í–‰
    
    Args:
        backtest_dir: ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë””ë ‰í† ë¦¬
        models_dir: ëª¨ë¸ ë””ë ‰í† ë¦¬
        
    Returns:
        ë¶„ì„ ê²°ê³¼
    """
    logger.info("ë¹ ë¥¸ ë¶„ì„ ì‹œì‘")
    
    analyzer = BacktestAnalyzer()
    
    # í•œê¸€ ì£¼ì„: ë°ì´í„° ë¡œë“œ
    analyzer.load_backtest_results(backtest_dir)
    
    # í•œê¸€ ì£¼ì„: ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    report = analyzer.generate_comprehensive_report()
    
    logger.info("ë¹ ë¥¸ ë¶„ì„ ì™„ë£Œ")
    return report

if __name__ == "__main__":
    # í•œê¸€ ì£¼ì„: ë¶„ì„ ë„êµ¬ ë‹¨ë… ì‹¤í–‰
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸ” 1ë…„ì¹˜ ë°±í…ŒìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘...")
    
    try:
        report = quick_analysis()
        
        print("\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        if report.get('trading_performance', {}).get('basic_stats'):
            stats = report['trading_performance']['basic_stats']
            print(f"   ì´ ê±°ë˜: {stats['total_trades']:,}ê±´")
            print(f"   ìŠ¹ë¥ : {stats['win_rate_pct']:.1f}%")
        
        if report.get('trading_performance', {}).get('risk_metrics'):
            risk = report['trading_performance']['risk_metrics']
            print(f"   ìƒ¤í”„ë¹„ìœ¨: {risk['sharpe_ratio']:.3f}")
            print(f"   ìµœëŒ€ë‚™í­: {risk['max_drawdown_pct']:.1f}%")
        
        print("\nğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:")
        for insight in report.get('key_insights', [])[:3]:
            print(f"   â€¢ {insight}")
        
        print("\nâœ… ë¶„ì„ ì™„ë£Œ! ìƒì„¸ ë¦¬í¬íŠ¸ê°€ data/reports/ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        logger.error(f"ë¶„ì„ ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

