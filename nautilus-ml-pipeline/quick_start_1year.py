"""
1ë…„ì¹˜ ìë™ë§¤ë§¤ ë°±í…ŒìŠ¤íŠ¸ + ML í›ˆë ¨ ë¹ ë¥¸ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
python quick_start_1year.py --symbol BTCUSDT --days 365
python quick_start_1year.py --symbol ETHUSDT --chunk-size 15
python quick_start_1year.py --all-symbols  # BTC, ETH ëª¨ë‘ ì‹¤í–‰
"""

import argparse
import asyncio
import logging
from datetime import datetime
import sys
from pathlib import Path

# í•œê¸€ ì£¼ì„: í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒ¨ìŠ¤ì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from run_1year_backtest import YearLongBacktestRunner
from ml_pipeline.large_dataset_trainer import train_large_dataset

# í•œê¸€ ì£¼ì„: ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def quick_start_single_symbol(
    symbol: str, 
    chunk_days: int = 30, 
    timeframe: str = "1m",
    use_large_trainer: bool = True
):
    """
    ë‹¨ì¼ ì‹¬ë³¼ 1ë…„ì¹˜ ë°±í…ŒìŠ¤íŠ¸ + ML í›ˆë ¨
    
    Args:
        symbol: ê±°ë˜ ì‹¬ë³¼ (ì˜ˆ: BTCUSDT)
        chunk_days: ì²­í¬ í¬ê¸° (ì¼)
        timeframe: ì‹œê°„ í”„ë ˆì„
        use_large_trainer: ëŒ€ìš©ëŸ‰ ë°ì´í„° í›ˆë ¨ê¸° ì‚¬ìš© ì—¬ë¶€
    """
    logger.info(f"ğŸš€ {symbol} 1ë…„ì¹˜ ë°±í…ŒìŠ¤íŠ¸ + ML í›ˆë ¨ ì‹œì‘")
    logger.info(f"ì„¤ì •: ì²­í¬ {chunk_days}ì¼, ì‹œê°„í”„ë ˆì„ {timeframe}")
    
    start_time = datetime.now()
    
    try:
        # í•œê¸€ ì£¼ì„: 1ë‹¨ê³„ - 1ë…„ì¹˜ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        logger.info("ğŸ“Š 1ë‹¨ê³„: 1ë…„ì¹˜ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        runner = YearLongBacktestRunner()
        
        backtest_report = await runner.run_year_long_backtest(
            symbol=symbol,
            chunk_days=chunk_days,
            timeframe=timeframe
        )
        
        trades_count = backtest_report['execution_summary']['total_trades_generated']
        logger.info(f"âœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {trades_count:,}ê±´ì˜ ê±°ë˜ ìƒì„±")
        
        # í•œê¸€ ì£¼ì„: 2ë‹¨ê³„ - ML ëª¨ë¸ í›ˆë ¨
        if trades_count > 100:  # ìµœì†Œ ê±°ë˜ ìˆ˜ í™•ì¸
            logger.info("ğŸ¤– 2ë‹¨ê³„: ML ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            
            # í•œê¸€ ì£¼ì„: ìµœì‹  í›ˆë ¨ ë°ì´í„° íŒŒì¼ ì°¾ê¸°
            training_data_dir = Path("data/training_data")
            training_files = list(training_data_dir.glob("training_data_*.csv"))
            
            if training_files:
                latest_file = max(training_files, key=lambda f: f.stat().st_mtime)
                logger.info(f"ìµœì‹  í›ˆë ¨ ë°ì´í„°: {latest_file.name}")
                
                # í•œê¸€ ì£¼ì„: ëŒ€ìš©ëŸ‰ ë°ì´í„° í›ˆë ¨ê¸° ì‚¬ìš©
                if use_large_trainer:
                    loop = asyncio.get_event_loop()
                    ml_metrics = await loop.run_in_executor(
                        None, 
                        train_large_dataset, 
                        str(latest_file), 
                        False  # incremental=False
                    )
                else:
                    # í•œê¸€ ì£¼ì„: ì¼ë°˜ í›ˆë ¨ê¸° ì‚¬ìš©
                    from ml_pipeline.model_trainer import train_new_model
                    loop = asyncio.get_event_loop()
                    model_path = await loop.run_in_executor(
                        None, 
                        train_new_model, 
                        str(latest_file)
                    )
                    ml_metrics = {'model_path': model_path}
                
                # í•œê¸€ ì£¼ì„: ML í›ˆë ¨ ê²°ê³¼ ì¶œë ¥
                if ml_metrics.get('test_r2'):
                    logger.info(f"âœ… ML ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
                    logger.info(f"   RÂ² ìŠ¤ì½”ì–´: {ml_metrics['test_r2']:.4f}")
                    logger.info(f"   RMSE: {ml_metrics.get('test_rmse', 'N/A')}")
                    
                    if ml_metrics.get('model_path'):
                        logger.info(f"   ëª¨ë¸ ì €ì¥: {Path(ml_metrics['model_path']).name}")
                else:
                    logger.warning("âš ï¸ ML ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨ ë˜ëŠ” ì„±ëŠ¥ ë¶€ì¡±")
            else:
                logger.error("âŒ í›ˆë ¨ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        else:
            logger.warning(f"âš ï¸ ê±°ë˜ ë°ì´í„° ë¶€ì¡± ({trades_count}ê±´) - ML í›ˆë ¨ ìŠ¤í‚µ")
        
        # í•œê¸€ ì£¼ì„: ìµœì¢… ê²°ê³¼ ìš”ì•½
        execution_time = (datetime.now() - start_time).total_seconds()
        logger.info(f"ğŸ‰ {symbol} ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        logger.info(f"   ì‹¤í–‰ ì‹œê°„: {execution_time/3600:.2f}ì‹œê°„")
        logger.info(f"   ìƒì„±ëœ ê±°ë˜: {trades_count:,}ê±´")
        
        return {
            'symbol': symbol,
            'success': True,
            'trades_generated': trades_count,
            'execution_time_hours': round(execution_time / 3600, 2),
            'backtest_report': backtest_report
        }
        
    except Exception as e:
        logger.error(f"âŒ {symbol} í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
        return {
            'symbol': symbol,
            'success': False,
            'error': str(e),
            'execution_time_hours': round((datetime.now() - start_time).total_seconds() / 3600, 2)
        }

async def quick_start_multiple_symbols(
    symbols: list, 
    chunk_days: int = 30,
    timeframe: str = "1m"
):
    """
    ì—¬ëŸ¬ ì‹¬ë³¼ ìˆœì°¨ ì‹¤í–‰
    
    Args:
        symbols: ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
        chunk_days: ì²­í¬ í¬ê¸°
        timeframe: ì‹œê°„ í”„ë ˆì„
    """
    logger.info(f"ğŸš€ ë‹¤ì¤‘ ì‹¬ë³¼ 1ë…„ì¹˜ ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘: {', '.join(symbols)}")
    
    results = []
    
    for i, symbol in enumerate(symbols, 1):
        logger.info(f"\n{'='*50}")
        logger.info(f"ì§„í–‰ ìƒí™©: {i}/{len(symbols)} - {symbol}")
        logger.info(f"{'='*50}")
        
        result = await quick_start_single_symbol(
            symbol=symbol,
            chunk_days=chunk_days,
            timeframe=timeframe
        )
        
        results.append(result)
        
        # í•œê¸€ ì£¼ì„: ì‹¬ë³¼ ê°„ íœ´ì‹ (ë§ˆì§€ë§‰ ì œì™¸)
        if i < len(symbols):
            logger.info(f"â³ ë‹¤ìŒ ì‹¬ë³¼ê¹Œì§€ 5ë¶„ ëŒ€ê¸°...")
            await asyncio.sleep(300)
    
    # í•œê¸€ ì£¼ì„: ì „ì²´ ê²°ê³¼ ìš”ì•½
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸŠ ì „ì²´ ë‹¤ì¤‘ ì‹¬ë³¼ ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    logger.info(f"{'='*60}")
    
    total_trades = sum(r.get('trades_generated', 0) for r in results)
    successful_symbols = [r['symbol'] for r in results if r['success']]
    failed_symbols = [r['symbol'] for r in results if not r['success']]
    
    logger.info(f"ì„±ê³µí•œ ì‹¬ë³¼: {', '.join(successful_symbols) if successful_symbols else 'ì—†ìŒ'}")
    if failed_symbols:
        logger.info(f"ì‹¤íŒ¨í•œ ì‹¬ë³¼: {', '.join(failed_symbols)}")
    logger.info(f"ì´ ìƒì„±ëœ ê±°ë˜: {total_trades:,}ê±´")
    
    return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="1ë…„ì¹˜ ìë™ë§¤ë§¤ ë°±í…ŒìŠ¤íŠ¸ + ML í›ˆë ¨ ë„êµ¬")
    
    # í•œê¸€ ì£¼ì„: ëª…ë ¹í–‰ ì¸ì ì„¤ì •
    parser.add_argument('--symbol', type=str, help='ê±°ë˜ ì‹¬ë³¼ (ì˜ˆ: BTCUSDT)')
    parser.add_argument('--all-symbols', action='store_true', help='ëª¨ë“  ì£¼ìš” ì‹¬ë³¼ ì‹¤í–‰ (BTC, ETH)')
    parser.add_argument('--chunk-size', type=int, default=30, help='ë°±í…ŒìŠ¤íŠ¸ ì²­í¬ í¬ê¸° (ì¼)')
    parser.add_argument('--timeframe', type=str, default='1m', choices=['1m', '5m', '1h'], help='ì‹œê°„ í”„ë ˆì„')
    parser.add_argument('--small-trainer', action='store_true', help='ì¼ë°˜ í›ˆë ¨ê¸° ì‚¬ìš© (ëŒ€ì‹  ëŒ€ìš©ëŸ‰ í›ˆë ¨ê¸°)')
    
    args = parser.parse_args()
    
    # í•œê¸€ ì£¼ì„: ì‹¤í–‰ ëª¨ë“œ ê²°ì •
    if args.all_symbols:
        symbols = ['BTCUSDT', 'ETHUSDT']
        logger.info(f"ğŸ¯ ë‹¤ì¤‘ ì‹¬ë³¼ ëª¨ë“œ: {', '.join(symbols)}")
        
        # í•œê¸€ ì£¼ì„: ë‹¤ì¤‘ ì‹¬ë³¼ ì‹¤í–‰
        results = asyncio.run(quick_start_multiple_symbols(
            symbols=symbols,
            chunk_days=args.chunk_size,
            timeframe=args.timeframe
        ))
        
    elif args.symbol:
        logger.info(f"ğŸ¯ ë‹¨ì¼ ì‹¬ë³¼ ëª¨ë“œ: {args.symbol}")
        
        # í•œê¸€ ì£¼ì„: ë‹¨ì¼ ì‹¬ë³¼ ì‹¤í–‰
        result = asyncio.run(quick_start_single_symbol(
            symbol=args.symbol,
            chunk_days=args.chunk_size,
            timeframe=args.timeframe,
            use_large_trainer=not args.small_trainer
        ))
        
        if result['success']:
            logger.info("âœ… í”„ë¡œì„¸ìŠ¤ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
        else:
            logger.error("âŒ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨")
            sys.exit(1)
    
    else:
        logger.error("âŒ --symbol ë˜ëŠ” --all-symbols ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”")
        parser.print_help()
        sys.exit(1)

if __name__ == "__main__":
    main()

