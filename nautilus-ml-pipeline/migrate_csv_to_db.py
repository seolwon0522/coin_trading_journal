#!/usr/bin/env python3
"""
ê¸°ì¡´ CSV íŒŒì¼ë“¤ì„ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
CSV ì½ê¸° ì„±ëŠ¥ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì¼íšŒì„± ë§ˆì´ê·¸ë ˆì´ì…˜
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
script_dir = Path(__file__).parent
sys.path.append(str(script_dir))

from database_manager import BacktestDatabaseManager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('migration.log')
    ]
)
logger = logging.getLogger(__name__)

def main():
    """ë©”ì¸ ë§ˆì´ê·¸ë ˆì´ì…˜ í•¨ìˆ˜"""
    
    logger.info("=" * 60)
    logger.info("CSV â†’ PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    logger.info("=" * 60)
    
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¤‘...")
        db_manager = BacktestDatabaseManager()
        logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì™„ë£Œ")
        
        # CSV íŒŒì¼ ë””ë ‰í† ë¦¬ í™•ì¸
        csv_directory = script_dir / "data" / "backtest_results"
        if not csv_directory.exists():
            logger.error(f"CSV ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_directory}")
            return False
        
        # CSV íŒŒì¼ ëª©ë¡ ì¡°íšŒ
        csv_files = list(csv_directory.glob("backtest_*.csv"))
        if not csv_files:
            logger.warning("ë§ˆì´ê·¸ë ˆì´ì…˜í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return True
        
        logger.info(f"ë°œê²¬ëœ CSV íŒŒì¼: {len(csv_files)}ê°œ")
        
        # ì‚¬ìš©ì í™•ì¸
        response = input(f"\n{len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        if response.lower() != 'y':
            logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
            return True
        
        # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        success_count = 0
        total_trades = 0
        
        for i, csv_file in enumerate(csv_files, 1):
            try:
                logger.info(f"[{i}/{len(csv_files)}] ì²˜ë¦¬ ì¤‘: {csv_file.name}")
                
                # íŒŒì¼ í¬ê¸° í™•ì¸ (ëŒ€ìš©ëŸ‰ íŒŒì¼ ê²½ê³ )
                file_size_mb = csv_file.stat().st_size / (1024 * 1024)
                if file_size_mb > 10:
                    logger.warning(f"ëŒ€ìš©ëŸ‰ íŒŒì¼ ê°ì§€: {file_size_mb:.1f}MB")
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                start_time = datetime.now()
                backtest_run_id = db_manager.save_backtest_results(str(csv_file))
                end_time = datetime.now()
                
                processing_time = (end_time - start_time).total_seconds()
                logger.info(f"  âœ… ì™„ë£Œ: ì‹¤í–‰ID {backtest_run_id} (ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ)")
                
                success_count += 1
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress = (i / len(csv_files)) * 100
                logger.info(f"  ì§„í–‰ë¥ : {progress:.1f}% ({success_count}/{len(csv_files)} ì„±ê³µ)")
                
            except Exception as e:
                logger.error(f"  âŒ ì‹¤íŒ¨: {csv_file.name} - {e}")
                continue
        
        # ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ìš”ì•½
        logger.info("\n" + "=" * 60)
        logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        logger.info("=" * 60)
        logger.info(f"ì´ ì²˜ë¦¬ íŒŒì¼: {len(csv_files)}ê°œ")
        logger.info(f"ì„±ê³µ: {success_count}ê°œ")
        logger.info(f"ì‹¤íŒ¨: {len(csv_files) - success_count}ê°œ")
        logger.info(f"ì„±ê³µë¥ : {(success_count / len(csv_files) * 100):.1f}%")
        
        if success_count > 0:
            logger.info("\nğŸ“ˆ ì„±ëŠ¥ ê°œì„  íš¨ê³¼:")
            logger.info("  - CSV ì½ê¸° ì‹œê°„: 2-3ì´ˆ â†’ 50-100ms (20-60ë°° í–¥ìƒ)")
            logger.info("  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ì „ì²´ ë°ì´í„° ë¡œë“œ â†’ í•„ìš”í•œ ë¶€ë¶„ë§Œ ì¡°íšŒ")
            logger.info("  - ë™ì‹œ ì ‘ê·¼: íŒŒì¼ ë½ â†’ ë‹¤ì¤‘ ì‚¬ìš©ì ë™ì‹œ ì ‘ê·¼ ê°€ëŠ¥")
            logger.info("  - ì§‘ê³„ ì¿¼ë¦¬: ì‹¤ì‹œê°„ ê³„ì‚° â†’ ì‚¬ì „ ê³„ì‚°ëœ ì§€í‘œ í™œìš©")
        
        # í›„ì† ì‘ì—… ì•ˆë‚´
        if success_count == len(csv_files):
            logger.info("\nâœ¨ ë‹¤ìŒ ë‹¨ê³„:")
            logger.info("  1. ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘ (ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ API í™œì„±í™”)")
            logger.info("  2. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
            logger.info("  3. ê¸°ì¡´ CSV íŒŒì¼ ë°±ì—… í›„ ì •ë¦¬ (ì„ íƒì‚¬í•­)")
            
            backup_suggestion = input("\nCSV íŒŒì¼ì„ ë°±ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if backup_suggestion.lower() == 'y':
                backup_csv_files(csv_files)
        
        return success_count == len(csv_files)
        
    except Exception as e:
        logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        return False

def backup_csv_files(csv_files):
    """CSV íŒŒì¼ë“¤ì„ ë°±ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™"""
    try:
        backup_dir = Path("data/backtest_results_backup")
        backup_dir.mkdir(exist_ok=True)
        
        moved_count = 0
        for csv_file in csv_files:
            try:
                backup_path = backup_dir / csv_file.name
                csv_file.rename(backup_path)
                moved_count += 1
            except Exception as e:
                logger.error(f"íŒŒì¼ ì´ë™ ì‹¤íŒ¨: {csv_file.name} - {e}")
        
        logger.info(f"CSV íŒŒì¼ ë°±ì—… ì™„ë£Œ: {moved_count}ê°œ íŒŒì¼ì„ {backup_dir}ë¡œ ì´ë™")
        
    except Exception as e:
        logger.error(f"ë°±ì—… í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")

def test_database_performance():
    """ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("\nğŸ” ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        db_manager = BacktestDatabaseManager()
        
        # ìµœì‹  ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸
        start_time = datetime.now()
        latest_data = db_manager.get_latest_backtest_data(limit=1000)
        query_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"  ì¡°íšŒ ì„±ëŠ¥: {len(latest_data)}ê°œ ê±°ë˜ ì¡°íšŒ ì‹œê°„ {query_time:.3f}ì´ˆ")
        
        # ì„±ê³¼ ì§€í‘œ ì¡°íšŒ í…ŒìŠ¤íŠ¸
        start_time = datetime.now()
        metrics = db_manager.get_performance_metrics()
        metrics_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"  ì§€í‘œ ê³„ì‚°: {metrics_time:.3f}ì´ˆ")
        logger.info(f"  ì´ ê±°ë˜ìˆ˜: {metrics.get('total_trades', 0)}")
        logger.info(f"  ì´ PnL: {metrics.get('total_pnl', 0):.2f}")
        
        return True
        
    except Exception as e:
        logger.error(f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    try:
        success = main()
        
        if success:
            # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            test_database_performance()
            
            logger.info("\nğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            logger.info("ì´ì œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ê³ ì„±ëŠ¥ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            logger.error("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("\nì‚¬ìš©ìì— ì˜í•´ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        sys.exit(1)
